{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What in this notebook\n",
    "\n",
    "- Running the code in `demo.ipynb` with the vulnerabilities dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onmt\n",
    "from onmt.inputters.inputter import _load_vocab, _build_fields_vocab, get_fields, IterOnDevice\n",
    "from onmt.inputters.corpus import ParallelCorpus\n",
    "from onmt.inputters.dynamic_iterator import DynamicDatasetIter\n",
    "from onmt.translate import GNMTGlobalScorer, Translator, TranslationBuilder\n",
    "from onmt.utils.misc import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from argparse import Namespace\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enable logging\n",
    "from onmt.utils.logging import init_logger, logger\n",
    "init_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_path = \"vul_data/data.vocab.src\"\n",
    "tgt_vocab_path = \"vul_data/data.vocab.tgt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-15 08:44:15,035 INFO] Loading src vocabulary from vul_data/data.vocab.src\n",
      "[2022-06-15 08:44:15,083 INFO] Loaded src vocab has 36442 tokens.\n",
      "[2022-06-15 08:44:15,093 INFO] Loading tgt vocabulary from vul_data/data.vocab.tgt\n",
      "[2022-06-15 08:44:15,100 INFO] Loaded tgt vocab has 5924 tokens.\n"
     ]
    }
   ],
   "source": [
    "# initialize the frequency counter\n",
    "counters = defaultdict(Counter)\n",
    "# load source vocab\n",
    "_src_vocab, _src_vocab_size = _load_vocab(\n",
    "    src_vocab_path,\n",
    "    'src',\n",
    "    counters)\n",
    "# load target vocab\n",
    "_tgt_vocab, _tgt_vocab_size = _load_vocab(\n",
    "    tgt_vocab_path,\n",
    "    'tgt',\n",
    "    counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize fields\n",
    "src_nfeats, tgt_nfeats = 0, 0 # do not support word features for now\n",
    "fields = get_fields(\n",
    "    'text', src_nfeats, tgt_nfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-15 08:44:24,059 INFO]  * tgt vocab size: 5928.\n",
      "[2022-06-15 08:44:24,085 INFO]  * src vocab size: 30002.\n"
     ]
    }
   ],
   "source": [
    "# build fields vocab\n",
    "share_vocab = False\n",
    "vocab_size_multiple = 1\n",
    "src_vocab_size = 30000\n",
    "tgt_vocab_size = 30000\n",
    "src_words_min_frequency = 1\n",
    "tgt_words_min_frequency = 1\n",
    "vocab_fields = _build_fields_vocab(\n",
    "    fields, counters, 'text', share_vocab,\n",
    "    vocab_size_multiple,\n",
    "    src_vocab_size, src_words_min_frequency,\n",
    "    tgt_vocab_size, tgt_words_min_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and optimizer creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text_field = vocab_fields[\"src\"].base_field\n",
    "src_vocab = src_text_field.vocab\n",
    "src_padding = src_vocab.stoi[src_text_field.pad_token]\n",
    "\n",
    "tgt_text_field = vocab_fields['tgt'].base_field\n",
    "tgt_vocab = tgt_text_field.vocab\n",
    "tgt_padding = tgt_vocab.stoi[tgt_text_field.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 100\n",
    "rnn_size = 500\n",
    "# Specify the core model.\n",
    "\n",
    "encoder_embeddings = onmt.modules.Embeddings(emb_size, len(src_vocab),\n",
    "                                             word_padding_idx=src_padding)\n",
    "\n",
    "encoder = onmt.encoders.RNNEncoder(hidden_size=rnn_size, num_layers=1,\n",
    "                                   rnn_type=\"LSTM\", bidirectional=True,\n",
    "                                   embeddings=encoder_embeddings)\n",
    "\n",
    "decoder_embeddings = onmt.modules.Embeddings(emb_size, len(tgt_vocab),\n",
    "                                             word_padding_idx=tgt_padding)\n",
    "decoder = onmt.decoders.decoder.InputFeedRNNDecoder(\n",
    "    hidden_size=rnn_size, num_layers=1, bidirectional_encoder=True, \n",
    "    rnn_type=\"LSTM\", embeddings=decoder_embeddings)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = onmt.models.model.NMTModel(encoder, decoder)\n",
    "model.to(device)\n",
    "\n",
    "# Specify the tgt word generator and loss computation module\n",
    "model.generator = nn.Sequential(\n",
    "    nn.Linear(rnn_size, len(tgt_vocab)),\n",
    "    nn.LogSoftmax(dim=-1)).to(device)\n",
    "\n",
    "loss = onmt.utils.loss.NMTLossCompute(\n",
    "    criterion=nn.NLLLoss(ignore_index=tgt_padding, reduction=\"sum\"),\n",
    "    generator=model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "torch_optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optim = onmt.utils.optimizers.Optimizer(\n",
    "    torch_optimizer, learning_rate=lr, max_grad_norm=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train = \"vul_data/random_fine_tune_train.src.txt\"\n",
    "tgt_train = \"vul_data/random_fine_tune_train.tgt.txt\"\n",
    "src_val = \"vul_data/random_fine_tune_valid.src.txt\"\n",
    "tgt_val = \"vul_data/random_fine_tune_valid.tgt.txt\"\n",
    "\n",
    "# build the ParallelCorpus\n",
    "corpus = ParallelCorpus(\"corpus\", src_train, tgt_train)\n",
    "valid = ParallelCorpus(\"valid\", src_val, tgt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the training iterator\n",
    "train_iter = DynamicDatasetIter(\n",
    "    corpora={\"corpus\": corpus},\n",
    "    corpora_info={\"corpus\": {\"weight\": 1}},\n",
    "    transforms={},\n",
    "    fields=vocab_fields,\n",
    "    is_train=True,\n",
    "    batch_type=\"tokens\",\n",
    "    batch_size=4096,\n",
    "    batch_size_multiple=1,\n",
    "    data_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the iteration happens on GPU 0 (-1 for CPU, N for GPU N)\n",
    "train_iter = iter(IterOnDevice(train_iter, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the validation iterator\n",
    "valid_iter = DynamicDatasetIter(\n",
    "    corpora={\"valid\": valid},\n",
    "    corpora_info={\"valid\": {\"weight\": 1}},\n",
    "    transforms={},\n",
    "    fields=vocab_fields,\n",
    "    is_train=False,\n",
    "    batch_type=\"sents\",\n",
    "    batch_size=8,\n",
    "    batch_size_multiple=1,\n",
    "    data_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = IterOnDevice(valid_iter, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-15 09:16:53,188 INFO] Start training loop and validate every 2000 steps...\n",
      "[2022-06-15 09:16:53,189 INFO] corpus's transforms: TransformPipe()\n",
      "[2022-06-15 09:16:53,189 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 1\n",
      "[2022-06-15 09:16:55,016 INFO] Step 600/10000; acc:  18.71; ppl: 192.75; xent: 5.26; lr: 0.00100; 52783/6709 tok/s;      2 sec\n",
      "[2022-06-15 09:16:58,372 INFO] Step 650/10000; acc:  19.85; ppl: 163.54; xent: 5.10; lr: 0.00100; 56003/4873 tok/s;      5 sec\n",
      "[2022-06-15 09:17:01,921 INFO] Step 700/10000; acc:  19.13; ppl: 175.59; xent: 5.17; lr: 0.00100; 53477/4649 tok/s;      9 sec\n",
      "[2022-06-15 09:17:04,183 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 2\n",
      "[2022-06-15 09:17:05,452 INFO] Step 750/10000; acc:  19.29; ppl: 172.78; xent: 5.15; lr: 0.00100; 52247/5676 tok/s;     12 sec\n",
      "[2022-06-15 09:17:08,794 INFO] Step 800/10000; acc:  19.98; ppl: 173.20; xent: 5.15; lr: 0.00100; 56049/5426 tok/s;     16 sec\n",
      "[2022-06-15 09:17:12,229 INFO] Step 850/10000; acc:  18.92; ppl: 177.22; xent: 5.18; lr: 0.00100; 54207/4912 tok/s;     19 sec\n",
      "[2022-06-15 09:17:15,107 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 3\n",
      "[2022-06-15 09:17:15,824 INFO] Step 900/10000; acc:  19.35; ppl: 170.67; xent: 5.14; lr: 0.00100; 51667/5714 tok/s;     23 sec\n",
      "[2022-06-15 09:17:19,421 INFO] Step 950/10000; acc:  19.55; ppl: 172.16; xent: 5.15; lr: 0.00100; 52494/5233 tok/s;     26 sec\n",
      "[2022-06-15 09:17:22,818 INFO] Step 1000/10000; acc:  19.04; ppl: 179.48; xent: 5.19; lr: 0.00100; 55432/5350 tok/s;     30 sec\n",
      "[2022-06-15 09:17:26,380 INFO] Step 1050/10000; acc:  19.48; ppl: 170.21; xent: 5.14; lr: 0.00100; 51632/5243 tok/s;     33 sec\n",
      "[2022-06-15 09:17:26,388 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 4\n",
      "[2022-06-15 09:17:29,994 INFO] Step 1100/10000; acc:  19.14; ppl: 178.57; xent: 5.18; lr: 0.00100; 52526/5201 tok/s;     37 sec\n",
      "[2022-06-15 09:17:33,488 INFO] Step 1150/10000; acc:  19.29; ppl: 174.75; xent: 5.16; lr: 0.00100; 53600/5407 tok/s;     40 sec\n",
      "[2022-06-15 09:17:37,090 INFO] Step 1200/10000; acc:  19.76; ppl: 156.12; xent: 5.05; lr: 0.00100; 51611/4865 tok/s;     44 sec\n",
      "[2022-06-15 09:17:37,650 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 5\n",
      "[2022-06-15 09:17:40,673 INFO] Step 1250/10000; acc:  19.46; ppl: 172.42; xent: 5.15; lr: 0.00100; 52128/5394 tok/s;     47 sec\n",
      "[2022-06-15 09:17:44,193 INFO] Step 1300/10000; acc:  18.97; ppl: 175.63; xent: 5.17; lr: 0.00100; 53179/5181 tok/s;     51 sec\n",
      "[2022-06-15 09:17:47,770 INFO] Step 1350/10000; acc:  19.48; ppl: 165.18; xent: 5.11; lr: 0.00100; 51878/5450 tok/s;     55 sec\n",
      "[2022-06-15 09:17:48,988 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 6\n",
      "[2022-06-15 09:17:51,435 INFO] Step 1400/10000; acc:  19.34; ppl: 171.43; xent: 5.14; lr: 0.00100; 51187/5366 tok/s;     58 sec\n",
      "[2022-06-15 09:17:54,950 INFO] Step 1450/10000; acc:  19.32; ppl: 168.26; xent: 5.13; lr: 0.00100; 52951/5076 tok/s;     62 sec\n",
      "[2022-06-15 09:17:58,475 INFO] Step 1500/10000; acc:  19.86; ppl: 160.91; xent: 5.08; lr: 0.00100; 53753/5040 tok/s;     65 sec\n",
      "[2022-06-15 09:18:00,125 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 7\n",
      "[2022-06-15 09:18:02,105 INFO] Step 1550/10000; acc:  19.24; ppl: 168.87; xent: 5.13; lr: 0.00100; 50519/5750 tok/s;     69 sec\n",
      "[2022-06-15 09:18:05,656 INFO] Step 1600/10000; acc:  19.37; ppl: 168.01; xent: 5.12; lr: 0.00100; 52469/4796 tok/s;     72 sec\n",
      "[2022-06-15 09:18:09,124 INFO] Step 1650/10000; acc:  19.69; ppl: 160.36; xent: 5.08; lr: 0.00100; 54720/4475 tok/s;     76 sec\n",
      "[2022-06-15 09:18:11,439 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 8\n",
      "[2022-06-15 09:18:12,875 INFO] Step 1700/10000; acc:  19.25; ppl: 166.80; xent: 5.12; lr: 0.00100; 49192/5502 tok/s;     80 sec\n",
      "[2022-06-15 09:18:16,461 INFO] Step 1750/10000; acc:  19.73; ppl: 171.59; xent: 5.15; lr: 0.00100; 52958/5133 tok/s;     83 sec\n",
      "[2022-06-15 09:18:19,930 INFO] Step 1800/10000; acc:  19.26; ppl: 164.37; xent: 5.10; lr: 0.00100; 53788/4874 tok/s;     87 sec\n",
      "[2022-06-15 09:18:22,747 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 9\n",
      "[2022-06-15 09:18:23,564 INFO] Step 1850/10000; acc:  20.04; ppl: 150.98; xent: 5.02; lr: 0.00100; 51245/5552 tok/s;     90 sec\n",
      "[2022-06-15 09:18:27,161 INFO] Step 1900/10000; acc:  19.81; ppl: 166.24; xent: 5.11; lr: 0.00100; 53363/5402 tok/s;     94 sec\n",
      "[2022-06-15 09:18:30,602 INFO] Step 1950/10000; acc:  19.58; ppl: 158.63; xent: 5.07; lr: 0.00100; 53418/4938 tok/s;     97 sec\n",
      "[2022-06-15 09:18:33,962 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 10\n",
      "[2022-06-15 09:18:34,179 INFO] Step 2000/10000; acc:  19.48; ppl: 168.40; xent: 5.13; lr: 0.00100; 52607/5702 tok/s;    101 sec\n",
      "[2022-06-15 09:18:34,180 INFO] valid's transforms: TransformPipe()\n",
      "[2022-06-15 09:18:35,240 INFO] Validation perplexity: 269.32\n",
      "[2022-06-15 09:18:35,241 INFO] Validation accuracy: 18.6719\n",
      "[2022-06-15 09:18:38,716 INFO] Step 2050/10000; acc:  19.50; ppl: 167.09; xent: 5.12; lr: 0.00100; 41694/4013 tok/s;    106 sec\n",
      "[2022-06-15 09:18:42,328 INFO] Step 2100/10000; acc:  19.48; ppl: 166.15; xent: 5.11; lr: 0.00100; 50988/5255 tok/s;    109 sec\n",
      "[2022-06-15 09:18:45,865 INFO] Step 2150/10000; acc:  20.00; ppl: 155.59; xent: 5.05; lr: 0.00100; 53003/5135 tok/s;    113 sec\n",
      "[2022-06-15 09:18:46,272 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 11\n",
      "[2022-06-15 09:18:49,508 INFO] Step 2200/10000; acc:  19.84; ppl: 160.64; xent: 5.08; lr: 0.00100; 51400/5456 tok/s;    116 sec\n",
      "[2022-06-15 09:18:53,092 INFO] Step 2250/10000; acc:  19.57; ppl: 161.96; xent: 5.09; lr: 0.00100; 52144/5201 tok/s;    120 sec\n",
      "[2022-06-15 09:18:56,528 INFO] Step 2300/10000; acc:  19.88; ppl: 155.68; xent: 5.05; lr: 0.00100; 54340/5143 tok/s;    123 sec\n",
      "[2022-06-15 09:18:57,517 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 12\n",
      "[2022-06-15 09:19:00,340 INFO] Step 2350/10000; acc:  19.75; ppl: 167.06; xent: 5.12; lr: 0.00100; 49335/5330 tok/s;    127 sec\n",
      "[2022-06-15 09:19:03,836 INFO] Step 2400/10000; acc:  20.46; ppl: 154.07; xent: 5.04; lr: 0.00100; 53227/5140 tok/s;    131 sec\n",
      "[2022-06-15 09:19:07,304 INFO] Step 2450/10000; acc:  19.74; ppl: 153.93; xent: 5.04; lr: 0.00100; 55044/5208 tok/s;    134 sec\n",
      "[2022-06-15 09:19:08,735 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 13\n",
      "[2022-06-15 09:19:10,845 INFO] Step 2500/10000; acc:  19.18; ppl: 167.25; xent: 5.12; lr: 0.00100; 52224/5715 tok/s;    138 sec\n",
      "[2022-06-15 09:19:14,374 INFO] Step 2550/10000; acc:  20.01; ppl: 152.55; xent: 5.03; lr: 0.00100; 52850/4738 tok/s;    141 sec\n",
      "[2022-06-15 09:19:17,965 INFO] Step 2600/10000; acc:  19.64; ppl: 160.29; xent: 5.08; lr: 0.00100; 52891/4669 tok/s;    145 sec\n",
      "[2022-06-15 09:19:21,486 INFO] Step 2650/10000; acc:  19.54; ppl: 163.99; xent: 5.10; lr: 0.00100; 51905/6211 tok/s;    148 sec\n",
      "[2022-06-15 09:19:25,071 INFO] Step 2700/10000; acc:  20.28; ppl: 155.39; xent: 5.05; lr: 0.00100; 52907/5093 tok/s;    152 sec\n",
      "[2022-06-15 09:19:28,574 INFO] Step 2750/10000; acc:  19.89; ppl: 157.58; xent: 5.06; lr: 0.00100; 53349/4623 tok/s;    155 sec\n",
      "[2022-06-15 09:19:31,060 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 14\n",
      "[2022-06-15 09:19:32,174 INFO] Step 2800/10000; acc:  19.90; ppl: 154.67; xent: 5.04; lr: 0.00100; 51718/5528 tok/s;    159 sec\n",
      "[2022-06-15 09:19:35,731 INFO] Step 2850/10000; acc:  20.24; ppl: 153.22; xent: 5.03; lr: 0.00100; 52929/5332 tok/s;    163 sec\n",
      "[2022-06-15 09:19:39,193 INFO] Step 2900/10000; acc:  19.69; ppl: 158.45; xent: 5.07; lr: 0.00100; 54521/4962 tok/s;    166 sec\n",
      "[2022-06-15 09:19:42,337 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 15\n",
      "[2022-06-15 09:19:42,883 INFO] Step 2950/10000; acc:  20.20; ppl: 150.88; xent: 5.02; lr: 0.00100; 49770/5221 tok/s;    170 sec\n",
      "[2022-06-15 09:19:46,305 INFO] Step 3000/10000; acc:  20.06; ppl: 158.77; xent: 5.07; lr: 0.00100; 55748/5492 tok/s;    173 sec\n",
      "[2022-06-15 09:19:49,825 INFO] Step 3050/10000; acc:  19.76; ppl: 160.70; xent: 5.08; lr: 0.00100; 52530/5102 tok/s;    177 sec\n",
      "[2022-06-15 09:19:53,363 INFO] Step 3100/10000; acc:  20.53; ppl: 146.92; xent: 4.99; lr: 0.00100; 52658/5443 tok/s;    180 sec\n",
      "[2022-06-15 09:19:53,541 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 16\n",
      "[2022-06-15 09:19:56,981 INFO] Step 3150/10000; acc:  19.97; ppl: 155.12; xent: 5.04; lr: 0.00100; 52226/5281 tok/s;    184 sec\n",
      "[2022-06-15 09:20:00,499 INFO] Step 3200/10000; acc:  19.95; ppl: 156.06; xent: 5.05; lr: 0.00100; 53535/5162 tok/s;    187 sec\n",
      "[2022-06-15 09:20:04,057 INFO] Step 3250/10000; acc:  20.02; ppl: 154.71; xent: 5.04; lr: 0.00100; 51773/5239 tok/s;    191 sec\n",
      "[2022-06-15 09:20:04,907 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 17\n",
      "[2022-06-15 09:20:07,715 INFO] Step 3300/10000; acc:  19.99; ppl: 159.77; xent: 5.07; lr: 0.00100; 51286/5296 tok/s;    195 sec\n",
      "[2022-06-15 09:20:11,181 INFO] Step 3350/10000; acc:  20.22; ppl: 148.22; xent: 5.00; lr: 0.00100; 54072/5014 tok/s;    198 sec\n",
      "[2022-06-15 09:20:14,746 INFO] Step 3400/10000; acc:  20.08; ppl: 152.39; xent: 5.03; lr: 0.00100; 52584/5337 tok/s;    202 sec\n",
      "[2022-06-15 09:20:16,237 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 18\n",
      "[2022-06-15 09:20:18,445 INFO] Step 3450/10000; acc:  19.99; ppl: 157.72; xent: 5.06; lr: 0.00100; 49502/5404 tok/s;    205 sec\n",
      "[2022-06-15 09:20:21,885 INFO] Step 3500/10000; acc:  20.10; ppl: 157.05; xent: 5.06; lr: 0.00100; 54179/4976 tok/s;    209 sec\n",
      "[2022-06-15 09:20:25,366 INFO] Step 3550/10000; acc:  19.93; ppl: 144.77; xent: 4.98; lr: 0.00100; 54509/4536 tok/s;    212 sec\n",
      "[2022-06-15 09:20:27,314 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 19\n",
      "[2022-06-15 09:20:29,062 INFO] Step 3600/10000; acc:  20.01; ppl: 153.88; xent: 5.04; lr: 0.00100; 49351/5984 tok/s;    216 sec\n",
      "[2022-06-15 09:20:32,598 INFO] Step 3650/10000; acc:  20.79; ppl: 146.43; xent: 4.99; lr: 0.00100; 54358/5006 tok/s;    219 sec\n",
      "[2022-06-15 09:20:36,172 INFO] Step 3700/10000; acc:  19.90; ppl: 146.86; xent: 4.99; lr: 0.00100; 52206/4612 tok/s;    223 sec\n",
      "[2022-06-15 09:20:38,623 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 20\n",
      "[2022-06-15 09:20:39,782 INFO] Step 3750/10000; acc:  20.27; ppl: 151.49; xent: 5.02; lr: 0.00100; 51382/5726 tok/s;    227 sec\n",
      "[2022-06-15 09:20:43,271 INFO] Step 3800/10000; acc:  20.56; ppl: 149.18; xent: 5.01; lr: 0.00100; 54504/5575 tok/s;    230 sec\n",
      "[2022-06-15 09:20:46,722 INFO] Step 3850/10000; acc:  19.78; ppl: 152.15; xent: 5.02; lr: 0.00100; 53070/4817 tok/s;    234 sec\n",
      "[2022-06-15 09:20:49,717 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 21\n",
      "[2022-06-15 09:20:50,334 INFO] Step 3900/10000; acc:  20.60; ppl: 145.92; xent: 4.98; lr: 0.00100; 50979/5309 tok/s;    237 sec\n",
      "[2022-06-15 09:20:53,958 INFO] Step 3950/10000; acc:  20.04; ppl: 160.23; xent: 5.08; lr: 0.00100; 52196/5346 tok/s;    241 sec\n",
      "[2022-06-15 09:20:57,268 INFO] Step 4000/10000; acc:  19.99; ppl: 142.54; xent: 4.96; lr: 0.00100; 56814/5237 tok/s;    244 sec\n",
      "[2022-06-15 09:20:58,307 INFO] Validation perplexity: 246.59\n",
      "[2022-06-15 09:20:58,308 INFO] Validation accuracy: 18.8177\n",
      "[2022-06-15 09:21:01,831 INFO] Step 4050/10000; acc:  20.87; ppl: 144.35; xent: 4.97; lr: 0.00100; 40135/4167 tok/s;    249 sec\n",
      "[2022-06-15 09:21:02,007 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 22\n",
      "[2022-06-15 09:21:05,400 INFO] Step 4100/10000; acc:  20.67; ppl: 146.16; xent: 4.98; lr: 0.00100; 53466/5262 tok/s;    252 sec\n",
      "[2022-06-15 09:21:09,073 INFO] Step 4150/10000; acc:  20.03; ppl: 156.19; xent: 5.05; lr: 0.00100; 51245/5100 tok/s;    256 sec\n",
      "[2022-06-15 09:21:12,475 INFO] Step 4200/10000; acc:  20.43; ppl: 135.11; xent: 4.91; lr: 0.00100; 55044/5027 tok/s;    259 sec\n",
      "[2022-06-15 09:21:13,163 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 23\n",
      "[2022-06-15 09:21:16,213 INFO] Step 4250/10000; acc:  19.84; ppl: 163.88; xent: 5.10; lr: 0.00100; 50503/5757 tok/s;    263 sec\n",
      "[2022-06-15 09:21:19,672 INFO] Step 4300/10000; acc:  20.17; ppl: 142.41; xent: 4.96; lr: 0.00100; 53732/5271 tok/s;    266 sec\n",
      "[2022-06-15 09:21:23,244 INFO] Step 4350/10000; acc:  20.42; ppl: 152.10; xent: 5.02; lr: 0.00100; 52375/5442 tok/s;    270 sec\n",
      "[2022-06-15 09:21:24,378 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 24\n",
      "[2022-06-15 09:21:26,834 INFO] Step 4400/10000; acc:  20.82; ppl: 150.88; xent: 5.02; lr: 0.00100; 52064/5387 tok/s;    274 sec\n",
      "[2022-06-15 09:21:30,373 INFO] Step 4450/10000; acc:  20.51; ppl: 149.07; xent: 5.00; lr: 0.00100; 53551/5225 tok/s;    277 sec\n",
      "[2022-06-15 09:21:33,828 INFO] Step 4500/10000; acc:  20.66; ppl: 139.79; xent: 4.94; lr: 0.00100; 54867/5167 tok/s;    281 sec\n",
      "[2022-06-15 09:21:35,421 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 25\n",
      "[2022-06-15 09:21:37,532 INFO] Step 4550/10000; acc:  20.31; ppl: 153.25; xent: 5.03; lr: 0.00100; 50017/5664 tok/s;    284 sec\n",
      "[2022-06-15 09:21:41,056 INFO] Step 4600/10000; acc:  20.97; ppl: 133.75; xent: 4.90; lr: 0.00100; 53383/4741 tok/s;    288 sec\n",
      "[2022-06-15 09:21:44,665 INFO] Step 4650/10000; acc:  20.38; ppl: 139.51; xent: 4.94; lr: 0.00100; 52535/4370 tok/s;    291 sec\n",
      "[2022-06-15 09:21:46,790 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 26\n",
      "[2022-06-15 09:21:48,234 INFO] Step 4700/10000; acc:  19.62; ppl: 156.63; xent: 5.05; lr: 0.00100; 51714/6070 tok/s;    295 sec\n",
      "[2022-06-15 09:21:51,710 INFO] Step 4750/10000; acc:  21.18; ppl: 139.19; xent: 4.94; lr: 0.00100; 54866/4884 tok/s;    299 sec\n",
      "[2022-06-15 09:21:55,290 INFO] Step 4800/10000; acc:  19.98; ppl: 150.23; xent: 5.01; lr: 0.00100; 51266/4926 tok/s;    302 sec\n",
      "[2022-06-15 09:21:59,044 INFO] Step 4850/10000; acc:  20.49; ppl: 145.20; xent: 4.98; lr: 0.00100; 49460/5535 tok/s;    306 sec\n",
      "[2022-06-15 09:22:02,581 INFO] Step 4900/10000; acc:  20.64; ppl: 144.15; xent: 4.97; lr: 0.00100; 53466/5239 tok/s;    309 sec\n",
      "[2022-06-15 09:22:06,142 INFO] Step 4950/10000; acc:  20.45; ppl: 146.19; xent: 4.98; lr: 0.00100; 52934/4829 tok/s;    313 sec\n",
      "[2022-06-15 09:22:09,359 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 27\n",
      "[2022-06-15 09:22:09,701 INFO] Step 5000/10000; acc:  20.75; ppl: 142.84; xent: 4.96; lr: 0.00100; 51435/5495 tok/s;    317 sec\n",
      "[2022-06-15 09:22:13,221 INFO] Step 5050/10000; acc:  20.50; ppl: 143.27; xent: 4.96; lr: 0.00100; 53236/5136 tok/s;    320 sec\n",
      "[2022-06-15 09:22:16,575 INFO] Step 5100/10000; acc:  20.41; ppl: 147.05; xent: 4.99; lr: 0.00100; 56475/5428 tok/s;    323 sec\n",
      "[2022-06-15 09:22:20,284 INFO] Step 5150/10000; acc:  20.61; ppl: 141.89; xent: 4.96; lr: 0.00100; 49784/5040 tok/s;    327 sec\n",
      "[2022-06-15 09:22:20,667 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 28\n",
      "[2022-06-15 09:22:23,869 INFO] Step 5200/10000; acc:  20.14; ppl: 151.08; xent: 5.02; lr: 0.00100; 52112/5444 tok/s;    331 sec\n",
      "[2022-06-15 09:22:27,380 INFO] Step 5250/10000; acc:  20.99; ppl: 141.56; xent: 4.95; lr: 0.00100; 53247/5315 tok/s;    334 sec\n",
      "[2022-06-15 09:22:30,858 INFO] Step 5300/10000; acc:  20.03; ppl: 140.94; xent: 4.95; lr: 0.00100; 53725/5114 tok/s;    338 sec\n",
      "[2022-06-15 09:22:31,919 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 29\n",
      "[2022-06-15 09:22:34,657 INFO] Step 5350/10000; acc:  20.41; ppl: 144.62; xent: 4.97; lr: 0.00100; 49338/5172 tok/s;    341 sec\n",
      "[2022-06-15 09:22:38,296 INFO] Step 5400/10000; acc:  20.61; ppl: 142.93; xent: 4.96; lr: 0.00100; 51621/5058 tok/s;    345 sec\n",
      "[2022-06-15 09:22:41,790 INFO] Step 5450/10000; acc:  20.27; ppl: 147.21; xent: 4.99; lr: 0.00100; 53875/5209 tok/s;    349 sec\n",
      "[2022-06-15 09:22:43,397 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 30\n",
      "[2022-06-15 09:22:45,466 INFO] Step 5500/10000; acc:  20.18; ppl: 148.01; xent: 5.00; lr: 0.00100; 50064/5631 tok/s;    352 sec\n",
      "[2022-06-15 09:22:49,013 INFO] Step 5550/10000; acc:  20.81; ppl: 145.54; xent: 4.98; lr: 0.00100; 53365/4844 tok/s;    356 sec\n",
      "[2022-06-15 09:22:52,406 INFO] Step 5600/10000; acc:  21.19; ppl: 131.84; xent: 4.88; lr: 0.00100; 55949/4548 tok/s;    359 sec\n",
      "[2022-06-15 09:22:54,591 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 31\n",
      "[2022-06-15 09:22:56,201 INFO] Step 5650/10000; acc:  20.14; ppl: 148.00; xent: 5.00; lr: 0.00100; 48177/5823 tok/s;    363 sec\n",
      "[2022-06-15 09:22:59,718 INFO] Step 5700/10000; acc:  20.93; ppl: 142.08; xent: 4.96; lr: 0.00100; 54541/5067 tok/s;    367 sec\n",
      "[2022-06-15 09:23:03,198 INFO] Step 5750/10000; acc:  20.55; ppl: 139.24; xent: 4.94; lr: 0.00100; 53665/4795 tok/s;    370 sec\n",
      "[2022-06-15 09:23:05,733 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 32\n",
      "[2022-06-15 09:23:06,758 INFO] Step 5800/10000; acc:  20.48; ppl: 141.60; xent: 4.95; lr: 0.00100; 51752/5664 tok/s;    374 sec\n",
      "[2022-06-15 09:23:10,382 INFO] Step 5850/10000; acc:  20.95; ppl: 141.24; xent: 4.95; lr: 0.00100; 52325/5275 tok/s;    377 sec\n",
      "[2022-06-15 09:23:13,977 INFO] Step 5900/10000; acc:  19.75; ppl: 147.13; xent: 4.99; lr: 0.00100; 51672/4770 tok/s;    381 sec\n",
      "[2022-06-15 09:23:17,102 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 33\n",
      "[2022-06-15 09:23:17,650 INFO] Step 5950/10000; acc:  21.18; ppl: 137.60; xent: 4.92; lr: 0.00100; 50644/5402 tok/s;    384 sec\n",
      "[2022-06-15 09:23:21,228 INFO] Step 6000/10000; acc:  21.19; ppl: 138.01; xent: 4.93; lr: 0.00100; 52698/5277 tok/s;    388 sec\n",
      "[2022-06-15 09:23:22,289 INFO] Validation perplexity: 235.798\n",
      "[2022-06-15 09:23:22,290 INFO] Validation accuracy: 19.1403\n",
      "[2022-06-15 09:23:25,564 INFO] Step 6050/10000; acc:  20.51; ppl: 139.65; xent: 4.94; lr: 0.00100; 43410/4053 tok/s;    392 sec\n",
      "[2022-06-15 09:23:29,169 INFO] Step 6100/10000; acc:  20.75; ppl: 140.70; xent: 4.95; lr: 0.00100; 51055/5237 tok/s;    396 sec\n",
      "[2022-06-15 09:23:29,435 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 34\n",
      "[2022-06-15 09:23:32,749 INFO] Step 6150/10000; acc:  20.65; ppl: 143.18; xent: 4.96; lr: 0.00100; 52563/5110 tok/s;    400 sec\n",
      "[2022-06-15 09:23:36,224 INFO] Step 6200/10000; acc:  20.82; ppl: 138.54; xent: 4.93; lr: 0.00100; 53487/5205 tok/s;    403 sec\n",
      "[2022-06-15 09:23:39,688 INFO] Step 6250/10000; acc:  20.80; ppl: 137.95; xent: 4.93; lr: 0.00100; 53954/5270 tok/s;    406 sec\n",
      "[2022-06-15 09:23:40,569 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 35\n",
      "[2022-06-15 09:23:43,452 INFO] Step 6300/10000; acc:  20.56; ppl: 146.21; xent: 4.99; lr: 0.00100; 50180/5351 tok/s;    410 sec\n",
      "[2022-06-15 09:23:46,937 INFO] Step 6350/10000; acc:  20.96; ppl: 138.25; xent: 4.93; lr: 0.00100; 53630/5257 tok/s;    414 sec\n",
      "[2022-06-15 09:23:50,512 INFO] Step 6400/10000; acc:  20.85; ppl: 139.48; xent: 4.94; lr: 0.00100; 53068/5238 tok/s;    417 sec\n",
      "[2022-06-15 09:23:51,917 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 36\n",
      "[2022-06-15 09:23:54,088 INFO] Step 6450/10000; acc:  20.62; ppl: 142.70; xent: 4.96; lr: 0.00100; 51528/5626 tok/s;    421 sec\n",
      "[2022-06-15 09:23:57,688 INFO] Step 6500/10000; acc:  20.60; ppl: 134.96; xent: 4.90; lr: 0.00100; 51819/5014 tok/s;    424 sec\n",
      "[2022-06-15 09:24:01,270 INFO] Step 6550/10000; acc:  20.52; ppl: 137.61; xent: 4.92; lr: 0.00100; 52995/4592 tok/s;    428 sec\n",
      "[2022-06-15 09:24:03,085 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 37\n",
      "[2022-06-15 09:24:04,933 INFO] Step 6600/10000; acc:  20.55; ppl: 148.46; xent: 5.00; lr: 0.00100; 50307/6245 tok/s;    432 sec\n",
      "[2022-06-15 09:24:08,528 INFO] Step 6650/10000; acc:  21.20; ppl: 132.29; xent: 4.89; lr: 0.00100; 53437/4796 tok/s;    435 sec\n",
      "[2022-06-15 09:24:11,949 INFO] Step 6700/10000; acc:  20.67; ppl: 135.85; xent: 4.91; lr: 0.00100; 53964/4707 tok/s;    439 sec\n",
      "[2022-06-15 09:24:14,299 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 38\n",
      "[2022-06-15 09:24:15,509 INFO] Step 6750/10000; acc:  20.56; ppl: 141.51; xent: 4.95; lr: 0.00100; 51953/5617 tok/s;    442 sec\n",
      "[2022-06-15 09:24:18,926 INFO] Step 6800/10000; acc:  21.40; ppl: 134.94; xent: 4.90; lr: 0.00100; 54919/5422 tok/s;    446 sec\n",
      "[2022-06-15 09:24:22,347 INFO] Step 6850/10000; acc:  21.07; ppl: 124.63; xent: 4.83; lr: 0.00100; 54499/4637 tok/s;    449 sec\n",
      "[2022-06-15 09:24:25,445 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 39\n",
      "[2022-06-15 09:24:26,121 INFO] Step 6900/10000; acc:  20.16; ppl: 148.39; xent: 5.00; lr: 0.00100; 49460/5682 tok/s;    453 sec\n",
      "[2022-06-15 09:24:29,632 INFO] Step 6950/10000; acc:  20.74; ppl: 140.61; xent: 4.95; lr: 0.00100; 54181/5374 tok/s;    456 sec\n",
      "[2022-06-15 09:24:33,166 INFO] Step 7000/10000; acc:  21.19; ppl: 131.13; xent: 4.88; lr: 0.00100; 52605/4970 tok/s;    460 sec\n",
      "[2022-06-15 09:24:36,838 INFO] Step 7050/10000; acc:  20.69; ppl: 141.42; xent: 4.95; lr: 0.00100; 50890/5568 tok/s;    464 sec\n",
      "[2022-06-15 09:24:40,318 INFO] Step 7100/10000; acc:  21.10; ppl: 130.82; xent: 4.87; lr: 0.00100; 54094/5092 tok/s;    467 sec\n",
      "[2022-06-15 09:24:43,836 INFO] Step 7150/10000; acc:  20.78; ppl: 143.61; xent: 4.97; lr: 0.00100; 53412/5217 tok/s;    471 sec\n",
      "[2022-06-15 09:24:47,392 INFO] Step 7200/10000; acc:  21.25; ppl: 129.94; xent: 4.87; lr: 0.00100; 52178/5206 tok/s;    474 sec\n",
      "[2022-06-15 09:24:47,911 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 40\n",
      "[2022-06-15 09:24:50,990 INFO] Step 7250/10000; acc:  20.62; ppl: 138.93; xent: 4.93; lr: 0.00100; 52002/5458 tok/s;    478 sec\n",
      "[2022-06-15 09:24:54,423 INFO] Step 7300/10000; acc:  21.06; ppl: 137.43; xent: 4.92; lr: 0.00100; 54791/5111 tok/s;    481 sec\n",
      "[2022-06-15 09:24:57,899 INFO] Step 7350/10000; acc:  21.19; ppl: 132.37; xent: 4.89; lr: 0.00100; 53867/5484 tok/s;    485 sec\n",
      "[2022-06-15 09:24:58,965 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 41\n",
      "[2022-06-15 09:25:01,541 INFO] Step 7400/10000; acc:  20.75; ppl: 136.55; xent: 4.92; lr: 0.00100; 51204/5268 tok/s;    488 sec\n",
      "[2022-06-15 09:25:05,029 INFO] Step 7450/10000; acc:  20.85; ppl: 133.81; xent: 4.90; lr: 0.00100; 53756/5221 tok/s;    492 sec\n",
      "[2022-06-15 09:25:08,682 INFO] Step 7500/10000; acc:  20.67; ppl: 137.43; xent: 4.92; lr: 0.00100; 51893/5096 tok/s;    495 sec\n",
      "[2022-06-15 09:25:10,329 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 42\n",
      "[2022-06-15 09:25:12,337 INFO] Step 7550/10000; acc:  21.06; ppl: 138.73; xent: 4.93; lr: 0.00100; 50334/5577 tok/s;    499 sec\n",
      "[2022-06-15 09:25:15,925 INFO] Step 7600/10000; acc:  21.55; ppl: 131.95; xent: 4.88; lr: 0.00100; 52942/4842 tok/s;    503 sec\n",
      "[2022-06-15 09:25:19,368 INFO] Step 7650/10000; acc:  20.62; ppl: 130.74; xent: 4.87; lr: 0.00100; 55099/4580 tok/s;    506 sec\n",
      "[2022-06-15 09:25:21,549 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 43\n",
      "[2022-06-15 09:25:22,984 INFO] Step 7700/10000; acc:  20.75; ppl: 138.39; xent: 4.93; lr: 0.00100; 50649/5929 tok/s;    510 sec\n",
      "[2022-06-15 09:25:26,563 INFO] Step 7750/10000; acc:  21.33; ppl: 132.31; xent: 4.89; lr: 0.00100; 53241/4755 tok/s;    513 sec\n",
      "[2022-06-15 09:25:30,083 INFO] Step 7800/10000; acc:  20.39; ppl: 136.30; xent: 4.91; lr: 0.00100; 52906/5138 tok/s;    517 sec\n",
      "[2022-06-15 09:25:32,983 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 44\n",
      "[2022-06-15 09:25:33,735 INFO] Step 7850/10000; acc:  20.99; ppl: 133.58; xent: 4.89; lr: 0.00100; 50690/5366 tok/s;    521 sec\n",
      "[2022-06-15 09:25:37,229 INFO] Step 7900/10000; acc:  20.91; ppl: 138.40; xent: 4.93; lr: 0.00100; 53735/5341 tok/s;    524 sec\n",
      "[2022-06-15 09:25:40,753 INFO] Step 7950/10000; acc:  21.08; ppl: 134.32; xent: 4.90; lr: 0.00100; 52822/5145 tok/s;    528 sec\n",
      "[2022-06-15 09:25:43,922 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 45\n",
      "[2022-06-15 09:25:44,267 INFO] Step 8000/10000; acc:  21.40; ppl: 131.00; xent: 4.88; lr: 0.00100; 52790/5552 tok/s;    531 sec\n",
      "[2022-06-15 09:25:45,403 INFO] Validation perplexity: 222.875\n",
      "[2022-06-15 09:25:45,404 INFO] Validation accuracy: 19.3381\n",
      "[2022-06-15 09:25:48,946 INFO] Step 8050/10000; acc:  20.67; ppl: 134.53; xent: 4.90; lr: 0.00100; 40581/3982 tok/s;    536 sec\n",
      "[2022-06-15 09:25:52,401 INFO] Step 8100/10000; acc:  20.87; ppl: 134.46; xent: 4.90; lr: 0.00100; 53343/5042 tok/s;    539 sec\n",
      "[2022-06-15 09:25:55,958 INFO] Step 8150/10000; acc:  21.58; ppl: 126.66; xent: 4.84; lr: 0.00100; 52481/5463 tok/s;    543 sec\n",
      "[2022-06-15 09:25:56,325 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 46\n",
      "[2022-06-15 09:25:59,644 INFO] Step 8200/10000; acc:  20.76; ppl: 139.43; xent: 4.94; lr: 0.00100; 50805/5085 tok/s;    546 sec\n",
      "[2022-06-15 09:26:03,120 INFO] Step 8250/10000; acc:  20.88; ppl: 133.75; xent: 4.90; lr: 0.00100; 54115/5299 tok/s;    550 sec\n",
      "[2022-06-15 09:26:06,699 INFO] Step 8300/10000; acc:  21.05; ppl: 130.09; xent: 4.87; lr: 0.00100; 52372/5312 tok/s;    554 sec\n",
      "[2022-06-15 09:26:07,623 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 47\n",
      "[2022-06-15 09:26:10,359 INFO] Step 8350/10000; acc:  20.99; ppl: 133.32; xent: 4.89; lr: 0.00100; 51147/5094 tok/s;    557 sec\n",
      "[2022-06-15 09:26:13,851 INFO] Step 8400/10000; acc:  20.80; ppl: 133.73; xent: 4.90; lr: 0.00100; 53295/5268 tok/s;    561 sec\n",
      "[2022-06-15 09:26:17,335 INFO] Step 8450/10000; acc:  21.24; ppl: 130.25; xent: 4.87; lr: 0.00100; 54394/5067 tok/s;    564 sec\n",
      "[2022-06-15 09:26:18,879 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 48\n",
      "[2022-06-15 09:26:20,922 INFO] Step 8500/10000; acc:  20.96; ppl: 136.78; xent: 4.92; lr: 0.00100; 51651/5895 tok/s;    568 sec\n",
      "[2022-06-15 09:26:24,502 INFO] Step 8550/10000; acc:  21.25; ppl: 132.40; xent: 4.89; lr: 0.00100; 52286/4879 tok/s;    571 sec\n",
      "[2022-06-15 09:26:27,981 INFO] Step 8600/10000; acc:  21.02; ppl: 130.47; xent: 4.87; lr: 0.00100; 54396/4582 tok/s;    575 sec\n",
      "[2022-06-15 09:26:30,020 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 49\n",
      "[2022-06-15 09:26:31,621 INFO] Step 8650/10000; acc:  20.59; ppl: 141.67; xent: 4.95; lr: 0.00100; 50411/6091 tok/s;    578 sec\n",
      "[2022-06-15 09:26:35,110 INFO] Step 8700/10000; acc:  21.93; ppl: 122.77; xent: 4.81; lr: 0.00100; 55263/4827 tok/s;    582 sec\n",
      "[2022-06-15 09:26:38,692 INFO] Step 8750/10000; acc:  21.00; ppl: 128.44; xent: 4.86; lr: 0.00100; 51953/4982 tok/s;    586 sec\n",
      "[2022-06-15 09:26:41,203 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 50\n",
      "[2022-06-15 09:26:42,334 INFO] Step 8800/10000; acc:  21.52; ppl: 134.61; xent: 4.90; lr: 0.00100; 51335/5519 tok/s;    589 sec\n",
      "[2022-06-15 09:26:45,897 INFO] Step 8850/10000; acc:  21.40; ppl: 132.58; xent: 4.89; lr: 0.00100; 53594/5623 tok/s;    593 sec\n",
      "[2022-06-15 09:26:49,313 INFO] Step 8900/10000; acc:  21.32; ppl: 126.32; xent: 4.84; lr: 0.00100; 54146/4659 tok/s;    596 sec\n",
      "[2022-06-15 09:26:52,218 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 51\n",
      "[2022-06-15 09:26:52,890 INFO] Step 8950/10000; acc:  20.87; ppl: 132.77; xent: 4.89; lr: 0.00100; 52278/5759 tok/s;    600 sec\n",
      "[2022-06-15 09:26:56,404 INFO] Step 9000/10000; acc:  20.90; ppl: 133.32; xent: 4.89; lr: 0.00100; 54057/5583 tok/s;    603 sec\n",
      "[2022-06-15 09:26:59,856 INFO] Step 9050/10000; acc:  20.86; ppl: 130.01; xent: 4.87; lr: 0.00100; 53344/5071 tok/s;    607 sec\n",
      "[2022-06-15 09:27:03,303 INFO] Step 9100/10000; acc:  21.59; ppl: 129.29; xent: 4.86; lr: 0.00100; 53624/5358 tok/s;    610 sec\n",
      "[2022-06-15 09:27:06,815 INFO] Step 9150/10000; acc:  20.96; ppl: 133.46; xent: 4.89; lr: 0.00100; 53851/5401 tok/s;    614 sec\n",
      "[2022-06-15 09:27:10,349 INFO] Step 9200/10000; acc:  21.49; ppl: 132.07; xent: 4.88; lr: 0.00100; 53092/5256 tok/s;    617 sec\n",
      "[2022-06-15 09:27:13,842 INFO] Step 9250/10000; acc:  21.91; ppl: 121.66; xent: 4.80; lr: 0.00100; 53393/5114 tok/s;    621 sec\n",
      "[2022-06-15 09:27:14,294 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 52\n",
      "[2022-06-15 09:27:17,415 INFO] Step 9300/10000; acc:  21.16; ppl: 132.57; xent: 4.89; lr: 0.00100; 52592/5413 tok/s;    624 sec\n",
      "[2022-06-15 09:27:20,931 INFO] Step 9350/10000; acc:  21.61; ppl: 127.19; xent: 4.85; lr: 0.00100; 53278/4979 tok/s;    628 sec\n",
      "[2022-06-15 09:27:24,505 INFO] Step 9400/10000; acc:  21.12; ppl: 129.92; xent: 4.87; lr: 0.00100; 52821/5536 tok/s;    631 sec\n",
      "[2022-06-15 09:27:25,586 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 53\n",
      "[2022-06-15 09:27:27,999 INFO] Step 9450/10000; acc:  20.72; ppl: 132.55; xent: 4.89; lr: 0.00100; 53248/5407 tok/s;    635 sec\n",
      "[2022-06-15 09:27:31,473 INFO] Step 9500/10000; acc:  21.48; ppl: 127.28; xent: 4.85; lr: 0.00100; 53710/5262 tok/s;    638 sec\n",
      "[2022-06-15 09:27:34,961 INFO] Step 9550/10000; acc:  21.41; ppl: 125.75; xent: 4.83; lr: 0.00100; 54379/5160 tok/s;    642 sec\n",
      "[2022-06-15 09:27:36,685 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 54\n",
      "[2022-06-15 09:27:38,720 INFO] Step 9600/10000; acc:  20.76; ppl: 134.02; xent: 4.90; lr: 0.00100; 48872/5577 tok/s;    646 sec\n",
      "[2022-06-15 09:27:42,251 INFO] Step 9650/10000; acc:  21.91; ppl: 124.83; xent: 4.83; lr: 0.00100; 53623/4825 tok/s;    649 sec\n",
      "[2022-06-15 09:27:45,731 INFO] Step 9700/10000; acc:  20.96; ppl: 125.80; xent: 4.83; lr: 0.00100; 54546/4496 tok/s;    653 sec\n",
      "[2022-06-15 09:27:48,100 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 55\n",
      "[2022-06-15 09:27:49,405 INFO] Step 9750/10000; acc:  21.10; ppl: 134.35; xent: 4.90; lr: 0.00100; 50611/5728 tok/s;    656 sec\n",
      "[2022-06-15 09:27:52,966 INFO] Step 9800/10000; acc:  21.59; ppl: 128.60; xent: 4.86; lr: 0.00100; 53485/5294 tok/s;    660 sec\n",
      "[2022-06-15 09:27:56,382 INFO] Step 9850/10000; acc:  21.60; ppl: 121.36; xent: 4.80; lr: 0.00100; 54459/4804 tok/s;    663 sec\n",
      "[2022-06-15 09:27:59,215 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 56\n",
      "[2022-06-15 09:28:00,073 INFO] Step 9900/10000; acc:  20.99; ppl: 130.95; xent: 4.87; lr: 0.00100; 50221/5537 tok/s;    667 sec\n",
      "[2022-06-15 09:28:03,609 INFO] Step 9950/10000; acc:  21.37; ppl: 132.88; xent: 4.89; lr: 0.00100; 53809/5575 tok/s;    670 sec\n",
      "[2022-06-15 09:28:07,020 INFO] Step 10000/10000; acc:  20.98; ppl: 130.42; xent: 4.87; lr: 0.00100; 54025/5005 tok/s;    674 sec\n",
      "[2022-06-15 09:28:08,069 INFO] Validation perplexity: 214.775\n",
      "[2022-06-15 09:28:08,069 INFO] Validation accuracy: 19.567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<onmt.utils.statistics.Statistics at 0x7f3e0c4708e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_manager = onmt.utils.ReportMgr(\n",
    "    report_every=50, start_time=None, tensorboard_writer=None)\n",
    "\n",
    "trainer = onmt.Trainer(model=model,\n",
    "                       train_loss=loss,\n",
    "                       valid_loss=loss,\n",
    "                       optim=optim,\n",
    "                       report_manager=report_manager,\n",
    "                       dropout=[0.1])\n",
    "\n",
    "trainer.train(train_iter=train_iter,\n",
    "              train_steps=10000,\n",
    "              valid_iter=valid_iter,\n",
    "              valid_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29040a093f9d049735cf0ac35f3fe0a5a8ac8d664da2716982ddb6534d95b6cf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('vrepair')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
