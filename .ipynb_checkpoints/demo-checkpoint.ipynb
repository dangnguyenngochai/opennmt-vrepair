{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onmt\n",
    "from onmt.inputters.inputter import _load_vocab, _build_fields_vocab, get_fields, IterOnDevice\n",
    "from onmt.inputters.corpus import ParallelCorpus\n",
    "from onmt.inputters.dynamic_iterator import DynamicDatasetIter\n",
    "from onmt.translate import GNMTGlobalScorer, Translator, TranslationBuilder\n",
    "from onmt.utils.misc import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from argparse import Namespace\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enable logging\n",
    "from onmt.utils.logging import init_logger, logger\n",
    "init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "set_random_seed(1111, is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy dataset is downloaded with this: `wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_config = \"\"\"\n",
    "## Where the samples will be written\n",
    "save_data: toy-ende/run/example\n",
    "## Where the vocab(s) will be written\n",
    "src_vocab: toy-ende/run/example.vocab.src\n",
    "tgt_vocab: toy-ende/run/example.vocab.tgt\n",
    "# Corpus opts:\n",
    "data:\n",
    "    corpus:\n",
    "        path_src: toy-ende/src-train.txt\n",
    "        path_tgt: toy-ende/tgt-train.txt\n",
    "        transforms: []\n",
    "        weight: 1\n",
    "    valid:\n",
    "        path_src: toy-ende/src-val.txt\n",
    "        path_tgt: toy-ende/tgt-val.txt\n",
    "        transforms: []\n",
    "\"\"\"\n",
    "config = yaml.safe_load(yaml_config)\n",
    "with open(\"toy-ende/config.yaml\", \"w\") as f:\n",
    "    f.write(yaml_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `config.yaml` file that used for building vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onmt.utils.parse import ArgumentParser\n",
    "parser = ArgumentParser(description='build_vocab.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the arguments parser for execution with `build_vocab.py` file\n",
    " \n",
    "**TO DO:** Detailize the vocabulary building process used for this translation task: english to french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onmt.opts import dynamic_prepare_opts\n",
    "dynamic_prepare_opts(parser, build_vocab_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_args = ([\"-config\", \"toy-ende/config.yaml\", \"-n_sample\", \"10000\", \"-overwrite\", \"True\"])\n",
    "opts, unknown = parser.parse_known_args(base_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above two cells creating a ``wrapper'' for the arguments to be parsed for building vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config='toy-ende/config.yaml', save_config=None, data=\"{'corpus': {'path_src': 'toy-ende/src-train.txt', 'path_tgt': 'toy-ende/tgt-train.txt', 'transforms': [], 'weight': 1}, 'valid': {'path_src': 'toy-ende/src-val.txt', 'path_tgt': 'toy-ende/tgt-val.txt', 'transforms': []}}\", skip_empty_level='warning', transforms=[], save_data='toy-ende/run/example', overwrite=True, n_sample=10000, dump_samples=False, num_threads=1, vocab_sample_queue_size=20, src_vocab='toy-ende/run/example.vocab.src', tgt_vocab='toy-ende/run/example.vocab.tgt', share_vocab=False, src_feats_vocab=None, src_subword_model=None, tgt_subword_model=None, src_subword_nbest=1, tgt_subword_nbest=1, src_subword_alpha=0, tgt_subword_alpha=0, src_subword_vocab='', tgt_subword_vocab='', src_vocab_threshold=0, tgt_vocab_threshold=0, src_subword_type='none', tgt_subword_type='none', src_onmttok_kwargs=\"{'mode': 'none'}\", tgt_onmttok_kwargs=\"{'mode': 'none'}\", src_seq_length=200, tgt_seq_length=200, switchout_temperature=1.0, tokendrop_temperature=1.0, tokenmask_temperature=1.0, reversible_tokenization='joiner', permute_sent_ratio=0.0, rotate_ratio=0.0, insert_ratio=0.0, random_ratio=0.0, mask_ratio=0.0, mask_length='subword', poisson_lambda=3.0, replace_length=-1, seed=-1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-15 16:03:28,076 INFO] Parsed 2 corpora from -data.\n",
      "[2022-06-15 16:03:28,077 INFO] Counter vocab from 10000 samples.\n",
      "[2022-06-15 16:03:28,077 INFO] Build vocab on 10000 transformed examples/corpus.\n",
      "[2022-06-15 16:03:28,081 INFO] corpus's transforms: TransformPipe()\n",
      "[2022-06-15 16:03:28,246 INFO] Counters src:24995\n",
      "[2022-06-15 16:03:28,246 INFO] Counters tgt:35816\n",
      "[2022-06-15 16:03:28,247 WARNING] path toy-ende/run/example.vocab.src exists, may overwrite...\n",
      "[2022-06-15 16:03:28,260 WARNING] path toy-ende/run/example.vocab.tgt exists, may overwrite...\n"
     ]
    }
   ],
   "source": [
    "from onmt.bin.build_vocab import build_vocab_main\n",
    "build_vocab_main(opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build fields\n",
    "Build the fields from the text files that were just created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** What are `fields` ? The following definition taken from [inputters documentation](https://opennmt.net/OpenNMT-py/onmt.inputters.html)\n",
    "> A dict with the structure returned by `onmt.inputters.get_fields()`. Usually that means the dataset side, `\"src\"` or `\"tgt\"`. Keys match the keys of items yielded by the readers, while values are lists of `(name, Field)` pairs. An attribute with this name will be created for each `torchtext.data.Example` object and its value will be the result of applying the Field to the data that matches the key. The advantage of having sequences of fields for each piece of raw input is that it allows the dataset to store multiple “views” of each input, which allows for easy implementation of token-level features, mixed word- and character-level models, and so on. (See also `onmt.inputters.TextMultiField`)\n",
    "\n",
    "In short, `field` defines how the input should be processed and having mulitple `fields` of input allow its to be processed in multiple granular-levels which are all can be used in the downstream modules as input for translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_path = \"toy-ende/run/example.vocab.src\"\n",
    "tgt_vocab_path = \"toy-ende/run/example.vocab.tgt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-15 16:22:49,137 INFO] Loading src vocabulary from toy-ende/run/example.vocab.src\n",
      "[2022-06-15 16:22:49,226 INFO] Loaded src vocab has 24995 tokens.\n",
      "[2022-06-15 16:22:49,233 INFO] Loading tgt vocabulary from toy-ende/run/example.vocab.tgt\n",
      "[2022-06-15 16:22:49,274 INFO] Loaded tgt vocab has 35816 tokens.\n"
     ]
    }
   ],
   "source": [
    "# initialize the frequency counter\n",
    "counters = defaultdict(Counter)\n",
    "# load source vocab\n",
    "_src_vocab, _src_vocab_size = _load_vocab(\n",
    "    src_vocab_path,\n",
    "    'src',\n",
    "    counters)\n",
    "# load target vocab\n",
    "_tgt_vocab, _tgt_vocab_size = _load_vocab(\n",
    "    tgt_vocab_path,\n",
    "    'tgt',\n",
    "    counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[['the', '12670'],\n",
      " [',', '9710'],\n",
      " ['.', '9647'],\n",
      " ['of', '6634'],\n",
      " ['and', '5787'],\n",
      " ['to', '5610'],\n",
      " ['in', '4072'],\n",
      " ['a', '3655'],\n",
      " ['is', '3138'],\n",
      " ['that', '2286']]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(type(_src_vocab))\n",
    "pprint(_src_vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize fields\n",
    "src_nfeats, tgt_nfeats = 0, 0 # do not support word features for now\n",
    "fields = get_fields(\n",
    "    'text', src_nfeats, tgt_nfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': <onmt.inputters.text_dataset.TextMultiField at 0x7f2ca0d2f970>,\n",
       " 'tgt': <onmt.inputters.text_dataset.TextMultiField at 0x7f2ca0d2ff40>,\n",
       " 'indices': <torchtext.data.field.Field at 0x7f2ca0d2f190>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-15 18:55:25,703 INFO]  * tgt vocab size: 30004.\n",
      "[2022-06-15 18:55:25,728 INFO]  * src vocab size: 24997.\n"
     ]
    }
   ],
   "source": [
    "# build fields vocab\n",
    "share_vocab = False # share vocab is turned off due to the fact of different syntax space between input and output, when activated the src_vocab_size and tgt_tgt_size are equal\n",
    "vocab_size_multiple = 1\n",
    "src_vocab_size = 30000\n",
    "tgt_vocab_size = 30000\n",
    "src_words_min_frequency = 1\n",
    "tgt_words_min_frequency = 1\n",
    "vocab_fields = _build_fields_vocab(\n",
    "    fields, counters, 'text', share_vocab,\n",
    "    vocab_size_multiple,\n",
    "    src_vocab_size, src_words_min_frequency,\n",
    "    tgt_vocab_size, tgt_words_min_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** An alternative way of creating these fields is to run onmt_train without actually training, to just output the necessary files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training: model and optimizer creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text_field = vocab_fields[\"src\"].base_field\n",
    "src_vocab = src_text_field.vocab\n",
    "src_padding = src_vocab.stoi[src_text_field.pad_token]\n",
    "\n",
    "tgt_text_field = vocab_fields['tgt'].base_field\n",
    "tgt_vocab = tgt_text_field.vocab\n",
    "tgt_padding = tgt_vocab.stoi[tgt_text_field.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 100\n",
    "rnn_size = 500\n",
    "# Specify the core model.\n",
    "\n",
    "encoder_embeddings = onmt.modules.Embeddings(emb_size, len(src_vocab),\n",
    "                                             word_padding_idx=src_padding)\n",
    "\n",
    "encoder = onmt.encoders.RNNEncoder(hidden_size=rnn_size, num_layers=1,\n",
    "                                   rnn_type=\"LSTM\", bidirectional=True,\n",
    "                                   embeddings=encoder_embeddings)\n",
    "\n",
    "decoder_embeddings = onmt.modules.Embeddings(emb_size, len(tgt_vocab),\n",
    "                                             word_padding_idx=tgt_padding)\n",
    "decoder = onmt.decoders.decoder.InputFeedRNNDecoder(\n",
    "    hidden_size=rnn_size, num_layers=1, bidirectional_encoder=True, \n",
    "    rnn_type=\"LSTM\", embeddings=decoder_embeddings)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = onmt.models.model.NMTModel(encoder, decoder)\n",
    "model.to(device)\n",
    "\n",
    "# Specify the tgt word generator and loss computation module\n",
    "model.generator = nn.Sequential(\n",
    "    nn.Linear(rnn_size, len(tgt_vocab)),\n",
    "    nn.LogSoftmax(dim=-1)).to(device)\n",
    "\n",
    "loss = onmt.utils.loss.NMTLossCompute(\n",
    "    criterion=nn.NLLLoss(ignore_index=tgt_padding, reduction=\"sum\"),\n",
    "    generator=model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "torch_optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optim = onmt.utils.optimizers.Optimizer(\n",
    "    torch_optimizer, learning_rate=lr, max_grad_norm=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training and validation data iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data iterators for loading the data and do pre-training data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train = \"toy-ende/src-train.txt\"\n",
    "tgt_train = \"toy-ende/tgt-train.txt\"\n",
    "src_val = \"toy-ende/src-val.txt\"\n",
    "tgt_val = \"toy-ende/tgt-val.txt\"\n",
    "\n",
    "# build the ParallelCorpus\n",
    "corpus = ParallelCorpus(\"corpus\", src_train, tgt_train)\n",
    "valid = ParallelCorpus(\"valid\", src_val, tgt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the training iterator\n",
    "train_iter = DynamicDatasetIter(\n",
    "    corpora={\"corpus\": corpus},\n",
    "    corpora_info={\"corpus\": {\"weight\": 1}},\n",
    "    transforms={},\n",
    "    fields=vocab_fields,\n",
    "    is_train=True,\n",
    "    batch_type=\"tokens\",\n",
    "    batch_size=4096,\n",
    "    batch_size_multiple=1,\n",
    "    data_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the iteration happens on GPU 0 (-1 for CPU, N for GPU N)\n",
    "train_iter = iter(IterOnDevice(train_iter, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the validation iterator\n",
    "valid_iter = DynamicDatasetIter(\n",
    "    corpora={\"valid\": valid},\n",
    "    corpora_info={\"valid\": {\"weight\": 1}},\n",
    "    transforms={},\n",
    "    fields=vocab_fields,\n",
    "    is_train=False,\n",
    "    batch_type=\"sents\",\n",
    "    batch_size=8,\n",
    "    batch_size_multiple=1,\n",
    "    data_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = IterOnDevice(valid_iter, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-15 07:58:47,711 INFO] Start training loop and validate every 500 steps...\n",
      "[2022-06-15 07:58:47,712 INFO] corpus's transforms: TransformPipe()\n",
      "[2022-06-15 07:58:47,713 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 1\n",
      "[2022-06-15 07:58:55,304 INFO] Step 50/ 1000; acc:   7.52; ppl: 8841.41; xent: 9.09; lr: 1.00000; 14836/14801 tok/s;      8 sec\n",
      "[2022-06-15 07:59:00,088 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 2\n",
      "[2022-06-15 07:59:02,966 INFO] Step 100/ 1000; acc:   9.45; ppl: 1917.17; xent: 7.56; lr: 1.00000; 14760/14661 tok/s;     15 sec\n",
      "[2022-06-15 07:59:10,697 INFO] Step 150/ 1000; acc:  10.71; ppl: 1375.01; xent: 7.23; lr: 1.00000; 14614/14579 tok/s;     23 sec\n",
      "[2022-06-15 07:59:15,824 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 3\n",
      "[2022-06-15 07:59:18,641 INFO] Step 200/ 1000; acc:  11.12; ppl: 1126.51; xent: 7.03; lr: 1.00000; 14351/14221 tok/s;     31 sec\n",
      "[2022-06-15 07:59:26,336 INFO] Step 250/ 1000; acc:  12.63; ppl: 911.46; xent: 6.82; lr: 1.00000; 14604/14600 tok/s;     39 sec\n",
      "[2022-06-15 07:59:31,772 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 4\n",
      "[2022-06-15 07:59:34,047 INFO] Step 300/ 1000; acc:  13.10; ppl: 778.70; xent: 6.66; lr: 1.00000; 14498/14430 tok/s;     46 sec\n",
      "[2022-06-15 07:59:41,806 INFO] Step 350/ 1000; acc:  13.94; ppl: 683.11; xent: 6.53; lr: 1.00000; 14569/14437 tok/s;     54 sec\n",
      "[2022-06-15 07:59:47,799 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 5\n",
      "[2022-06-15 07:59:49,597 INFO] Step 400/ 1000; acc:  14.96; ppl: 595.89; xent: 6.39; lr: 1.00000; 14535/14486 tok/s;     62 sec\n",
      "[2022-06-15 07:59:57,350 INFO] Step 450/ 1000; acc:  15.90; ppl: 526.64; xent: 6.27; lr: 1.00000; 14418/14271 tok/s;     70 sec\n",
      "[2022-06-15 08:00:03,498 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 6\n",
      "[2022-06-15 08:00:04,706 INFO] Step 500/ 1000; acc:  16.85; ppl: 460.69; xent: 6.13; lr: 1.00000; 14701/14786 tok/s;     77 sec\n",
      "[2022-06-15 08:00:04,707 INFO] valid's transforms: TransformPipe()\n",
      "[2022-06-15 08:00:15,640 INFO] Validation perplexity: 311.226\n",
      "[2022-06-15 08:00:15,640 INFO] Validation accuracy: 15.4113\n",
      "[2022-06-15 08:00:23,284 INFO] Step 550/ 1000; acc:  17.47; ppl: 420.38; xent: 6.04; lr: 1.00000; 6237/6143 tok/s;     96 sec\n",
      "[2022-06-15 08:00:30,341 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 7\n",
      "[2022-06-15 08:00:31,166 INFO] Step 600/ 1000; acc:  19.02; ppl: 355.89; xent: 5.87; lr: 1.00000; 13526/13625 tok/s;    103 sec\n",
      "[2022-06-15 08:00:38,892 INFO] Step 650/ 1000; acc:  19.61; ppl: 327.96; xent: 5.79; lr: 1.00000; 14992/14833 tok/s;    111 sec\n",
      "[2022-06-15 08:00:46,109 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 8\n",
      "[2022-06-15 08:00:46,479 INFO] Step 700/ 1000; acc:  20.70; ppl: 286.93; xent: 5.66; lr: 1.00000; 14425/14370 tok/s;    119 sec\n",
      "[2022-06-15 08:00:53,985 INFO] Step 750/ 1000; acc:  21.85; ppl: 249.30; xent: 5.52; lr: 1.00000; 15145/15060 tok/s;    126 sec\n",
      "[2022-06-15 08:01:01,639 INFO] Step 800/ 1000; acc:  22.49; ppl: 229.18; xent: 5.43; lr: 1.00000; 14543/14461 tok/s;    134 sec\n",
      "[2022-06-15 08:01:01,807 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 9\n",
      "[2022-06-15 08:01:09,315 INFO] Step 850/ 1000; acc:  24.40; ppl: 193.36; xent: 5.26; lr: 1.00000; 14605/14581 tok/s;    142 sec\n",
      "[2022-06-15 08:01:14,536 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 10\n",
      "[2022-06-15 08:01:17,220 INFO] Step 900/ 1000; acc:  24.72; ppl: 178.63; xent: 5.19; lr: 1.00000; 14211/14065 tok/s;    150 sec\n",
      "[2022-06-15 08:01:24,653 INFO] Step 950/ 1000; acc:  26.22; ppl: 156.67; xent: 5.05; lr: 1.00000; 14796/14759 tok/s;    157 sec\n",
      "[2022-06-15 08:01:30,132 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus: 11\n",
      "[2022-06-15 08:01:32,102 INFO] Step 1000/ 1000; acc:  27.36; ppl: 137.90; xent: 4.93; lr: 1.00000; 14815/14833 tok/s;    164 sec\n",
      "[2022-06-15 08:01:43,461 INFO] Validation perplexity: 231.265\n",
      "[2022-06-15 08:01:43,461 INFO] Validation accuracy: 20.4819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<onmt.utils.statistics.Statistics at 0x7ff7932573d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_manager = onmt.utils.ReportMgr(\n",
    "    report_every=50, start_time=None, tensorboard_writer=None)\n",
    "\n",
    "trainer = onmt.Trainer(model=model,\n",
    "                       train_loss=loss,\n",
    "                       valid_loss=loss,\n",
    "                       optim=optim,\n",
    "                       report_manager=report_manager,\n",
    "                       dropout=[0.1])\n",
    "\n",
    "trainer.train(train_iter=train_iter,\n",
    "              train_steps=1000,\n",
    "              valid_iter=valid_iter,\n",
    "              valid_steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For translation, we can build a \"traditional\" (as opposed to dynamic) dataset for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = {\"reader\": onmt.inputters.str2reader[\"text\"](), \"data\": src_val, \"features\": {}}\n",
    "tgt_data = {\"reader\": onmt.inputters.str2reader[\"text\"](), \"data\": tgt_val, \"features\": {}}\n",
    "_readers, _data = onmt.inputters.Dataset.config([('src', src_data), ('tgt', tgt_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = onmt.inputters.Dataset(\n",
    "    vocab_fields, readers=_readers, data=_data,\n",
    "    sort_key=onmt.inputters.str2sortkey[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = onmt.inputters.OrderedIterator(\n",
    "            dataset=dataset,\n",
    "            device=\"cuda\",\n",
    "            batch_size=10,\n",
    "            train=False,\n",
    "            sort=False,\n",
    "            sort_within_batch=True,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_reader = onmt.inputters.str2reader[\"text\"]\n",
    "tgt_reader = onmt.inputters.str2reader[\"text\"]\n",
    "scorer = GNMTGlobalScorer(alpha=0.7, \n",
    "                          beta=0., \n",
    "                          length_penalty=\"avg\", \n",
    "                          coverage_penalty=\"none\")\n",
    "gpu = 0 if torch.cuda.is_available() else -1\n",
    "translator = Translator(model=model, \n",
    "                        fields=vocab_fields, \n",
    "                        src_reader=src_reader, \n",
    "                        tgt_reader=tgt_reader, \n",
    "                        global_scorer=scorer,\n",
    "                        gpu=gpu)\n",
    "builder = onmt.translate.TranslationBuilder(data=dataset, \n",
    "                                            fields=vocab_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: translations will be very poor, because of the very low quantity of data, the absence of proper tokenization, and the brevity of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SENT 0: ['Parliament', 'Does', 'Not', 'Support', 'Amendment', 'Freeing', 'Tymoshenko']\n",
      "PRED 0: Parlament das Parlament auf , die sich in der Lage , die sich in der Lage <unk> .\n",
      "PRED SCORE: -1.5629\n",
      "\n",
      "\n",
      "SENT 0: ['Today', ',', 'the', 'Ukraine', 'parliament', 'dismissed', ',', 'within', 'the', 'Code', 'of', 'Criminal', 'Procedure', 'amendment', ',', 'the', 'motion', 'to', 'revoke', 'an', 'article', 'based', 'on', 'which', 'the', 'opposition', 'leader', ',', 'Yulia', 'Tymoshenko', ',', 'was', 'sentenced', '.']\n",
      "PRED 0: In der Nähe des Hotels in der Nähe des Hotels , die in der Lage , die in der Lage , die in der Lage , in der Lage ist .\n",
      "PRED SCORE: -1.7963\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'amendment', 'that', 'would', 'lead', 'to', 'freeing', 'the', 'imprisoned', 'former', 'Prime', 'Minister', 'was', 'revoked', 'during', 'second', 'reading', 'of', 'the', 'proposal', 'for', 'mitigation', 'of', 'sentences', 'for', 'economic', 'offences', '.']\n",
      "PRED 0: Die Tatsache , die sich in der Lage waren , um die für eine Antwort zu geben .\n",
      "PRED SCORE: -1.6795\n",
      "\n",
      "\n",
      "SENT 0: ['In', 'October', ',', 'Tymoshenko', 'was', 'sentenced', 'to', 'seven', 'years', 'in', 'prison', 'for', 'entering', 'into', 'what', 'was', 'reported', 'to', 'be', 'a', 'disadvantageous', 'gas', 'deal', 'with', 'Russia', '.']\n",
      "PRED 0: In der Nähe des Hotels wurde in der Nähe des Landes <unk> und wurde .\n",
      "PRED SCORE: -1.6518\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'verdict', 'is', 'not', 'yet', 'final;', 'the', 'court', 'will', 'hear', 'Tymoshenko', '&apos;s', 'appeal', 'in', 'December', '.']\n",
      "PRED 0: In der Nähe des Hotels wird sie in der Schweiz nicht <unk> .\n",
      "PRED SCORE: -1.4944\n",
      "\n",
      "\n",
      "SENT 0: ['Tymoshenko', 'claims', 'the', 'verdict', 'is', 'a', 'political', 'revenge', 'of', 'the', 'regime;', 'in', 'the', 'West', ',', 'the', 'trial', 'has', 'also', 'evoked', 'suspicion', 'of', 'being', 'biased', '.']\n",
      "PRED 0: In der Lage in der Lage in der Lage .\n",
      "PRED SCORE: -1.4420\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'proposal', 'to', 'remove', 'Article', '365', 'from', 'the', 'Code', 'of', 'Criminal', 'Procedure', ',', 'upon', 'which', 'the', 'former', 'Prime', 'Minister', 'was', 'sentenced', ',', 'was', 'supported', 'by', '147', 'members', 'of', 'parliament', '.']\n",
      "PRED 0: Das <unk> <unk> de la <unk> de la <unk> de la <unk> de la <unk> de <unk> de <unk> .\n",
      "PRED SCORE: -1.5613\n",
      "\n",
      "\n",
      "SENT 0: ['Its', 'ratification', 'would', 'require', '226', 'votes', '.']\n",
      "PRED 0: Es wäre schon <unk> .\n",
      "PRED SCORE: -1.6132\n",
      "\n",
      "\n",
      "SENT 0: ['Libya', '&apos;s', 'Victory']\n",
      "PRED 0: In der Nähe des Hotels in der Lage .\n",
      "PRED SCORE: -1.8560\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'story', 'of', 'Libya', '&apos;s', 'liberation', ',', 'or', 'rebellion', ',', 'already', 'has', 'its', 'defeated', '.']\n",
      "PRED 0: In der Nähe des Hotels in der Nähe des Hotels , oder in der Lage .\n",
      "PRED SCORE: -1.7644\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgm/miniconda3/envs/vrepair/lib/python3.10/site-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self._batch_index = self.topk_ids // vocab_size\n"
     ]
    }
   ],
   "source": [
    "for batch in data_iter:\n",
    "    trans_batch = translator.translate_batch(\n",
    "        batch=batch, src_vocabs=[src_vocab],\n",
    "        attn_debug=False)\n",
    "    translations = builder.from_batch(trans_batch)\n",
    "    for trans in translations:\n",
    "        print(trans.log(0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29040a093f9d049735cf0ac35f3fe0a5a8ac8d664da2716982ddb6534d95b6cf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('vrepair')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
